embedding:
  cam_dev: "/dev/video2"
  pixfmt: "YUYV"
  width: 848
  height: 480
  fps: 6

  # TinyMobileNet runtime spec (must match pretrain)
  input_size: 128
  out_dim: 128
  width_scale: 0.35
  fp16: false          # ONNX CPU → 비활성화
  use_depthwise: false # ← 학습 기본값을 썼다면 false
  use_bn: false        # ← 학습 기본값을 썼다면 false
  pinned: false        # ONNX 경로에선 의미 거의 없음(무시 가능)

  # img2emb 전용 ROI (center-based, w,h / dx,dy)
  roi_px: [530, 530]
  roi_offset: [90, -130]

  # 런타임에 로드할 ONNX 모델 경로
  weights_path: "model/weights/tinymnet_emb_128d_w035.onnx"

  # E2E warmup
  e2e_warmup_frames: 12
  e2e_pregrab: 2

depth:
  width: 1280
  height: 720
  fps: 6
  roi_px: [250, 260]
  roi_offset: [15, -80]
  DECIM: 1
  PLANE_TAU: 0.004
  H_MIN_BASE: 0.003
  H_MAX: 0.4
  MIN_OBJ_PIX: 40
  BOTTOM_ROI_RATIO: 0.20
  HOLE_FILL: false
  CORE_MARGIN_PX: 1
  P_LO: 1.0
  P_HI: 99.0

datamatrix:
  camera: 2
  prefer_res: [1920, 1080]
  prefer_fps: 6
  decode_interval: 0.20
  log_every_decode: 0
  max_backoff: 1.0
  rois:
    - name: ROI_LEFT_MIRROR
      size: [390, 500]
      offset: [-450, -140]
      hflip: true
    - name: ROI_RIGHT_MIRROR
      size: [390, 490]
      offset: [660, -140]
      hflip: true
    - name: ROI_MAIN
      size: [530, 530]
      offset: [90, -130]
      hflip: false

quality:
  q_warn: 0.30

storage:
  sqlite_path: "pack.db"

model:
  # 사용 우선순위: "lgbm" | "centroid"
  # (LGBM 모델 파일이 있을 경우 "lgbm" 권장)
  type: "lgbm"
  centroids_path: "centroids.npz"
  lgbm_path: "lgbm.pkl"
  topk: 3

lgbm:
  n_estimators: 200
  num_leaves: 31
  learning_rate: 0.05
  min_data_in_leaf: 10
  feature_fraction: 0.8
  bagging_fraction: 0.8
  bagging_freq: 1
  class_weight: "balanced"
  seed: 42

training:
  min_count: 2
  min_q: 0.0

arduino:
  port: "/dev/ttyACM0"
  baudrate: 9600
